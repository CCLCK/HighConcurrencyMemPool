# 池化技术

把一些能够复用的东西放到池中，避免重复创建、销毁的开销，从而提高性能。

程序先向系统申请过量的资源，然后自己管理，以备多次申请。之所以要申请过量的资源，是因为每次申请该资源都有较大的开销，不如提前申请好了，这样用起来就会非常快捷，大大提高了程序的运行效率。比如内存池、连接池、线程池、对象池等。

我们这里的内存池也是同理，一次性申请一大块内存，之后什么时候要就从这大块内存取。

> 方便理解“池”的概念，我住山上，山上水资源紧缺，我每次用水都要去山下打水，那我自然会想建造一个池子，我一次性担很多水放到池子里，我要的时候里直接去池子里取就行了，相比于每次去山下的开销，显然在自己家附近建造一个池子的开销更小，而且更加快捷。

池化技术避免了反复的申请，减少了开销。 

# 内存池解决的问题

1. 效率的问题

生活费，我每次花钱都找爸妈，所以每次花钱前都要和爸妈沟通。 有了池化技术，我知道每个月大概要花八百块，那月初就向爸妈要八百块，那我每次用钱的时候就不用和爸妈沟通了，自己从小钱包里拿钱就行了。

内存池同理，每次要都像系统要，效率不高，不如一次申请好，要用就从池子里拿。

> 用了内存池，申请时的开销大一点，但是用起来就很快。

2. 内存碎片问题

申请空间要求这块空间是连续的。所以会导致一种情况，内存里的空间是够的，但是碎片化了，也就是不连续，导致空间够了但我申请不出来。这就是内存碎片问题，导致我本该能申请出来的空间申请不出来了。

> 碎片分为内碎片和外碎片。下图表示的是外碎片
>
> ![image-20220819161910228](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220819161910228.png)
>
> 假设申请了四块空间，然后有了四块碎片，这四块碎片是不连续的，如果这四块碎片加起来是36KB，我们现在申请一个36KB大小的内存，会发现虽然可用的空间有36KB，但是因为碎片化了申请不出来。所以我们应该尽量避免碎片的产生。



# malloc的相关知识

- tcmalloc和malloc的对比:[TCMalloc与Malloc对比](https://blog.csdn.net/jinguanding/article/details/6543583)
- C和C++申请内存靠的是malloc，malloc向进程地址空间里的堆申请内存。
- c++常用new，我的理解new就是对malloc的封装，为什么要封装呢？符合C++一些抛异常的机制。
- 我们可以自定义operator new来自定义new，同时也可以通过定位new使得malloc可以调用构造方法。
- malloc也是一个内存池，进程调用malloc->库里调用brk()找操作系统要内存->操作系统执行brk(),brk（）返回，malloc找到空闲内存块，申请内存成功，malloc返回。linux里有个函数sbrk()，是对brk()的封装。
- 如果我们用malloc去申请8字节的内存，一定不是只找系统要8字节，而是一次性要一个批量，比如一百万字节，这一百万字节就是池子，然后从池子里拿出八字节给malloc。
- malloc的底层实现是ptmalloc。

## 玩具malloc原理简述

> **下面的malloc只是简单的玩具，实际上远比这复杂。**
>
> 这块找到的资料零零散散的，而且理解比较浅，有错误的地方敬请指出。
>
> 而且malloc的实现方式太多了，链表，位图，哈希桶等。。。

malloc也是采用的内存池技术，malloc用块来描述内存，每个块头上几个字节存储地址，表示next指针，接下来用一个标识来表示这块空间是否被使用（一般是一个比特位），再之后才是有效载荷或空闲的内存。将可用的空闲内存块通过next指针串起来，也就是链表。链表又分为单链表和双链表，大多数malloc的实现会采用双链表，利于内存块的合并和拆分。加上池化技术，malloc会一次从系统申请大块内存，然后进行管理。

![image-20220819155205859](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220819155205859.png)

> 代码实现上，块用结构体描述，里面会加许多别的属性，如块的大小等

malloc申请：

- 在链表上找到一个内存块给malloc，然后把这一块从链表上拿下来。
- 关于怎么在链表上找到这个内存块，有两种策略，一种是best fit，一种是first fit，best fit会找最合适的，比如有一块16KB，一块24KB的内存，我们要8KB，那best fit就会给16KB的，而first fit会找第一个匹配的。很多都会采用first fit，因为块，有点空间换时间的意思。
- 小于128KB的调用brk()，大于128KB的调用mmap()
- 如果我们要8KB，内存块是128KB，或者更大，那就会对这个128kb进行切分（split），切一块8KB的返回给malloc(用户)，剩下的120KB依旧放在链表中，之后更改描述这个内存块的结构体属性即可。（这里有种操作系统管理的意味：操作的都是抽象出来的结构体，而不是说真的对这块内存做了什么。）

free释放：

- 块有个属性描述这个块是否在被使用，我们就知道当前要释放的块是否被使用，如果这块内存没被使用我们还free就会造成free两次的效果，此时在代码实现上就要对其进行相应的处理。
- 如果当前内存块确实在被使用，那还回去的过程就是链接到空闲链表的过程，链接上链表后，我们要检测当前块的上一个块和下一个块，如果上一个块或下一个块没有被使用，那就进行合并，合并之后得到一个更大的块，下次我们申请就可以申请出一个更大的块了，缓解了内存碎片的问题。

> 块虽然是链表连接起来的，但相当一部分内存块在物理上也是连续的。

## ptmalloc简述

> 参考资料：
>
> [Linux进程分配内存的两种方式--brk() 和mmap()](https://www.cnblogs.com/vinozly/p/5489138.html)
>
> [malloc的底层实现（ptmalloc）](https://blog.csdn.net/z_ryan/article/details/79950737)

ptmalloc是glibc的内存管理器。glibc是GNU发布的c运行库。

### 铺垫

复习下基础知识

> 进程地址空间的存在让每个进程都专注于自己的事情，保证了进程的独立性，同时可以保护物理内存，直接访问物理内存不安全。

![image-20220820000447417](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220820000447417.png)

> 前面提过linux里的sbrk()本质是对brk()的封装。
>
> _edata指针指向数据段的最高地址（我暂时理解为堆顶指针。。。

小于128KB的会调用brk将指针_edata向上推，大于128KB的直接调用mmap，从栈和堆直接分配一块虚拟内存。大于128K的使用完直接调用unmmap还给系统。

此外malloc只是分配了虚拟内存，并没有建立与物理内存的联系，第一次访问发生缺页中断才会建立与物理内存的映射。

> 缺页中断：陷入内核态->检查虚拟地址是否合法->合法分配物理页->填充物理页->建立映射。如果不合法的话会报页缺失的错误。

网上经常看到一句话：高地址的内存没释放，低地址的也不能释放，我对这句话的理解是：高地址的没释放，_edata指针不能往回缩紧，缩紧的意思可以理解为合并两块内存，如果两块或者多块内存合并后**大于128KB（有些说是64KB）**，那就执行内存紧缩操作，即把 _edata指针往回退而不是真的说高地址内存没释放低地址就不能释放了（我们free的时候没有一定的要求，不过建议是后malloc的先free，利于减少内存碎片）

![image-20220820002646850](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220820002646850.png)

### chunk

> 参考资料：
>
> [ptmalloc分配区 - 搜索 (bing.com)](https://cn.bing.com/search?q=ptmalloc分配区&qs=n&form=QBRE&sp=-1&pq=ptmalloc分配qu&sc=0-12&sk=&cvid=C03C4E79A60A4A9A800FFD4711050692&ghsh=0&ghacc=0&ghpl=)
>
> [ptmalloc,tcmalloc和jemalloc内存分配策略研究 ](https://cloud.tencent.com/developer/article/1173720#:~:text=Ptmalloc,在进行内存分配。)
>
> [一篇文章彻底讲懂malloc的实现（ptmalloc）](https://blog.csdn.net/songchuwang1868/article/details/89951543)
>
> [Linux c 开发 - 内存管理器ptmalloc](https://zhuanlan.zhihu.com/p/352445428)

上面几篇讲的很清楚了，这篇文章里这个知识点不是重点，但事实上ptmalloc里内存的分配和释放和chunk这个结构紧密相关。

chunk结构可以理解为一个结构体，里面有着我们要的一些属性，比如chunk的大小，比如指向前一个chunk的指针，以及前一个chunk的大小等，这些属性的作用是便于内存的管理。

我对此只是简单的了解，ptmalloc给了多个bin（链表），申请的内存情况有很多种，有很小的，很大的，中规中矩的，对于每种内存有相应的bin，比如小内存找fast bin，大内存找top chunk，如果很大很大，那直接就找系统要了。合并的时候同理，小内存如果合并成大内存就也要更改所在的bin，通过这种方式就可以通过多个链表把这些内存管理起来了。

> 摘自上面某篇文章：
>
> 小内存： [获取分配区(arena)并加锁] -> fast bin -> unsorted bin -> small bin -> large bin -> top chunk -> 扩展堆
>
> 大内存： 直接mmap

### 线程安全

最开始了解ptmalloc的原因就是因为线程安全，我们这文章主要的目的是实现mini版的tcmalloc，为什么要写tcmalloc，因为高并发下tcmalloc比malloc优秀很多，要知道0为什么tcmalloc比malloc优秀很多我们显然得先知道malloc是怎么保证线程安全的。

先给结论：**malloc是线程安全的，但是不可重入。**

malloc保证线程安全是通过**分区和加锁**实现的。

- 在内存分配器ptmalloc中，分为主分配区和非主分配区，本质都是内存池。主分配区和非主分配区借助环形链表管理
- 每个进程有一个主分配区，允许有多个非主分配区，每个分配区借助互斥锁使得访问这个分配区时不被别的线程打扰
- 主分配区可以使用brk和mmap分配，非主分配区使用mmap分配（与那个128K没啥关系）。申请小内存时会产生很多内存碎片，ptmalloc整理时也要对分配区加锁。
- 举个例子：一个线程找malloc分配内存，先看这个线程的私有变量中是否存在一个分配区，有的话就尝试加锁，加锁成功就会用这个分配区分配内存，不成功遍历循环链表找到未加锁的，找不到就创一个新的再加锁，然后再分配内存。释放时也要先获取内存所在的分配区的锁，如果别的线程在用这个分配区就得等。可以看出如果每个线程都私有一个分配区的话就可以避免竞争，此时就引出了TLS（TLS是线程内各个函数都有的，别的线程看不到的，被称之为线程局部静态变量，thread local static），有了TLS就可以更快的找到分配区，tcmalloc也用到了TLS。虽然如此，malloc仍然需要多次加锁解锁，导致并发下效率不佳，而且用久了会有比较多的外碎片，所以多线程下建议用tcmalloc，tcmalloc利用一些方法使得不用频繁的加锁解锁。

关于malloc线程**安全但是不可重入**：

> 参考资料：[malloc线程安全但不可重入？？](https://zhuanlan.zhihu.com/p/371222679)
>
> [malloc的可重入性和线程安全分析 ](https://www.cnblogs.com/shihuvini/p/10142317.html)
>
> [malloc是否是线程安全的？](https://www.cnblogs.com/tomren/archive/2011/12/24/2300602.html)
>
> 我只是对上面的资料整合并且说一下自己的理解，理解上没有这些大佬那么透彻。

根据上面文章说的，malloc应该使用递归锁（可重入互斥锁）来避免信号中断带来的线程安全问题。如果一个进程执行malloc时收到了一个信号，之后进程中断去执行信号处理函数，如果信号处理函数里也有malloc，那可能导致**死锁**，因为第一次malloc的锁释放前就被中断了一直没释放，所以**得用递归锁**。

虽然这保证了malloc函数的线程安全，但是**递归锁进去时可能破坏了共享的链表等资源**，所以malloc是不能重入的。

此外破坏的资源是不可知的，所以执行malloc时被信号打断导致的结果是不可预料的，也因此我们说malloc虽然线程安全但是是不可重入的。（**malloc的锁是分配区的锁**，所以如果是同一个线程通过递归锁多次进入一个同一个分配区，即一个线程多次进入一个分配区，导致的问题是不可知的，但如果是不同的线程想进入同一个分配区，一般进入分配区前会提前尝试加锁，加锁失败就会去找别的分配区，也就保证了线程安全，此外递归锁的原理是**计数器+记录线程号**来保证同一线程可以多次进入一个函数放同时不会死锁）

简单来说，递归锁让不同线程不能同时进入一个分配区，也保证了一个线程递归调用malloc不死锁，但是正因为他允许一个线程多次进入malloc，使得malloc多次进入可能破坏一些资源，即malloc不可重入。

说白了就是这里用递归锁给了malloc重入的可能性，但碰到信号这样的malloc就可能会破坏当前进程的环境，或者说是资源，如一些锁，链表等，但不用递归锁的话我们又无法保证线程安全。

这也说明**可重入函数一定线程安全，线程安全不一定可重入**。

### 小结

了解上面那些是为了更好的理解tcmalloc,知道tcmalloc为什么比malloc在高并发下**更稳定、效率更高**。

> 尺有所短寸有所长,malloc和tcmalloc都有自己的长短处,malloc的一些算法也是很多年前写的了，tcmalloc是谷歌里一群顶尖工程师写的，go语言的内存管理器也采用了开源的tcmalloc，tcmalloc整个项目是很庞大的，细节也很多，这里我们写的高并发内存池只不过是项目里的一角，对比真正的tcmalloc就是玩具，管中窥豹，可见一斑。

# 实现一个定长内存池

定长内存池比作一个大块的长条内存，要的时候就切一块下来，特点是性能极致，没有碎片的问题，因为每次切都是连续连续的切，切下来的内存由自由链表管理。

[(15条消息) 【项目设计】高并发内存池_2021dragon的博客-CSDN博客](https://blog.csdn.net/chenlong_cxy/article/details/122819562?spm=1001.2014.3001.5502)

[(15条消息) 【C/C++实现 MiniTcMalloc】高并发内存池项目_^jhao^的博客-CSDN博客_c++ tcmalloc](https://blog.csdn.net/weixin_52344401/article/details/123975636?spm=1001.2014.3001.5501)

[C++高并发内存池如何实现 - 开发技术 - 亿速云 (yisu.com)](https://www.yisu.com/zixun/724492.html#:~:text=定长内存池就是针,定大小的内存块。)

![image-20220808001141404](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220808001141404.png)



用完了还回去不能还给系统 得还给池子 池子统一还给系统

固定大小的内存申请释放需求

特点：

性能达到极致

不考虑内存碎片的问题





整一块

![image-20220808002231130](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220808002231130.png)

不断的切就行了



管理还回来的内存：自由链表

用头四个字节存下一个快的地址，最后一个指向NULL

![image-20220808002735921](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220808002735921.png)





![image-20220808003756171](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220808003756171.png)



剩余内存不够一个对象大小时则重新开大块空间

![image-20220808004931188](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220808004931188.png)

解决64位下指针大小8字节的问题

 ![image-20220808010500197](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220808010500197.png)









```cpp
void Delete(T* obj)
{
    //还回来一个对象
    if (_freeList == nullptr)//第一次
    {
        _freeList = obj;
        //*((int*)obj) = nullptr;//64位下就有问题了
        *((void**)obj) = nullptr;//解决64位下指针大小8字节的问题
    }
    else//头插，单链表找尾麻烦
    {
        *(void**)obj = _freeList;
        _freeList = obj;
    }
}
```

![image-20220808011209314](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220808011209314.png)

![image-20220808011317982](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220808011317982.png)





利用还回来的内存。

![image-20220808012449431](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220808012449431.png)

初始化和销毁空间

![image-20220808012923621](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220808012923621.png)



测试

对比malloc 快七倍左右

virutual alloc



brk mmap



# 高并发内存池整体框架设计

知道大方向是怎么样的

![image-20220808223723161](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220808223723161.png)



![image-20220808224008278](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220808224008278.png)





每个线程都有自己的 缓存  线程从这里申请内存不需要加锁 （申请的内存小于256KB）大于256的找别的地方



thread cache没有内存就去central cache,多个线程去找central cache就有线程安全问题了 要加锁

central cache实现是哈希桶 访问同一个桶时才加锁 访问不同桶就不用管了，锁竞争就没那么激烈了

而且只有thread1和thread2同时去找central cache才加锁 所以锁竞争不激烈

thread cache也不是只出不进 也会回收一些内存 还给central cache 起到均衡调度的作用  

![image-20220808230557227](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220808230557227.png)



thread cache解决锁竞争的问题

之前那个定长内存池切得是定长，那如果开的是任意字节呢？

难道针对每个字节都去搞一个自由链表吗？不合理 因为以256KB为例就二十多万字节了，那建二十多万个自由链表吗？

做一些平衡的牺牲，第一个链表挂8 第二个挂16 第三个挂24等等

要10字节给十六字节等，有一点空间浪费，多给一点是可以接受的

要了5个字节 给了八个  有三个永远用不上 也就是内存碎片 这种叫做内碎片（因为一些对齐的原因产生碎片化的内存）



内碎片是由于对齐等原因造成的，外碎片是一些连续的空间被切成多块 不连续导致申请不出来（有足够的空间申请不出需要的空间）

thread_cache是哈希桶结构， 



虽然每个桶的表示的字节数不同 但是结构都是一样的 都是头上几个字节指向下一个

![image-20220808234616460](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220808234616460.png)



![image-20220808235542112](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220808235542112.png)



专门写一个类管理映射规则：因为哈希映射的是一个范围



![image-20220809101043591](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220809101043591.png)

以八字节为基础去对齐  因为64位下一个指针都是8字节  至少要能存的下一个指针



以八字节为间隔 要建立这么多个链表 可以是可以 但是有点多

![image-20220809101426689](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220809101426689.png)

![image-20220809101538601](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220809101538601.png)



普通人玩的

![image-20220809104928986](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220809104928986.png)



这样保证算出来的都是8的倍数  对齐数为16时同理

![image-20220809130354886](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220809130354886.png)

![image-20220809130734626](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220809130734626.png)





深入理解计算机系统 dataLab



![image-20220809133806800](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220809133806800.png)



TLS 线程本地存储 pdf里找链接

![image-20220809152315925](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220809152315925.png)





![image-20220809153945842](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220809153945842.png)

 NextObj在多个cpp包含 每个obj都有一个NextObj 链接时就冲突了



第一层有就去自由链表拿 没有就去下一层

第二层就要桶锁

 span--跨度

给thread cache span ,span是多页的大快内存



span用完了的话， 自由链表里的span就指向空了

![image-20220809162003619](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220809162003619.png)

thread cache下面的太多了要还给span



usecount是一个计数器 用来计数span分出去多少块 可以知道span分配的和还回来的状态

减到0说明所有申请的都还给了span

带头双向循环链表——》central cache

 

2^10是1K

![image-20220809164557078](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220809164557078.png)

最后编号会编出2^19个页



但是64位的程序 2^64/2 ^13=2 ^51个页 页数就大了

![image-20220809165105360](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220809165105360.png)

页数的解决

![image-20220809165159788](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220809165159788.png)



每个线程有自己独享的thread cache 要求全局只有一个central cache供大家看到 所以需要单例模式





page cache的结构



![image-20220810020825351](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220810020825351.png)



刚好1M可以给4个256KB

![image-20220810021146460](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220810021146460.png)



这里的系统指的是堆，没有申请一个128page的，然后再分给小的

![image-20220810100059035](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220810100059035.png)

![image-20220810100641137](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220810100641137.png)



thread cache太长就还给central cache

central cache的useCount减到0了 就还给page cache



![image-20220810101451952](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220810101451952.png)

![image-20220810120854993](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220810120854993.png)





尾插

![image-20220810122302411](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220810122302411.png)























![image-20220810152648354](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220810152648354.png)













![image-20220810153347182](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220810153347182.png)





 回收



![image-20220810214149685](https://pic-1304888003.cos.ap-guangzhou.myqcloud.com/img/image-20220810214149685.png)





usecount不能判断span在第二层还是在第三层 可能刚切好就被拿去合并了





1. 解决bug
2. 回收机制
3. 介绍引言

--------------------------------
